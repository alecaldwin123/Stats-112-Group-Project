---
title: "Residual Model"
author: "Jay, Alec, Lynn"
date: "5/21/2021"
output: pdf_document
---
```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(nlme)
library(mgcv)
aids = read.csv("aids.csv")


aids = aids %>% 
  mutate(occasion = ceiling(week),
         gender = factor(gender, level = c("male", "female")),
         treatment = as.factor(treatment))

glimpse(aids)
```

# Current Model  

```{r}
aids <- aids %>% 
    mutate(knot_term1 = if_else((treatment == 4 & occasion <= 16), occasion^2, 0)) %>% 
    relocate(knot_term1, .after = occasion)


ctrl <- lmeControl(opt = 'optim')
model_spline2 = lme(log_cd4 ~ occasion + 
             treatment:occasion + age + knot_term1,
             data = aids,
             random = ~ occasion | id,
             method = "REML",
             control = ctrl)


summary(model_spline2)

```

```{r}
model_quadratic = lme(log_cd4 ~ occasion + I(occasion^2) + 
             treatment:occasion + treatment:I(occasion^2)
               +  age, data = aids,
             random = ~ occasion + I(occasion^2)| id,
             method = "REML")

summary(model_quadratic)
```

```{r}
#Anova on our two models above
anova(model_spline2, model_quadratic)
```
An ANOVA analysis on our two models above demonstrates that the quadratic model seems to be a better fit for the data that we are given. A significant p-value (p < 0.001) further verifies this assertion. 

# Residual Analysis  

## Histogram of Transformed and Non-transformed Residuals  
```{r}

res_prog = residuals(model_quadratic, level = 0)


sigma_i = extract.lme.cov(model_quadratic, aids)

#lower triangular matrix
L_i = t(chol(sigma_i))

#transformed residuals
res_prog_trans = solve(L_i) %*% res_prog


tibble(r = res_prog_trans) %>% 
  ggplot(aes(x = r)) +
  geom_histogram(aes(y = stat(density)), bins = 14 ) +
  geom_function(fun = dnorm, color = "blue")
```
This plot shows the density of our transformed residuals. It appears that our transformed residuals seem to follow a Normal distribution, or at the very least, a a symmetric distribution. 



```{r}
tibble(r = res_prog) %>% 
  ggplot(aes(x = r)) +
  geom_histogram(aes(y = stat(density)), bins = 14 ) +
  geom_function(fun = dnorm, color = "blue")
```
This plot shows the distribution of our residuals (without any transformation). The distribution appears to be a little more left-skewed in comparison to the histogram of our transformed residuals. 

## QQ-Plot  
```{r}
tibble(r = res_prog_trans) %>% 
  ggplot(aes(sample = r)) + 
  geom_qq_line(color = "blue") +
  geom_qq()
```
<<<<<<< HEAD
The qq plot reveals the tails for the distribution of our residuals are quite heavy. This brings into question whether or not the residuals actually follow a normal distribution. Furthermore, several lingering points at the end of each tail suggest that we may have outliers present in our dataset (this is further discussed in the mahalanobis data section below). 

=======

## Transformed Predicted values vs. Transformed Residuals  
```{r}
#transformed vs actual residual
mu_hat = fitted(model_quadratic, level = 0)
mu_hat_transformed = solve(L_i) %*% mu_hat


tibble(x = mu_hat_transformed, y = res_prog_trans) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_point(shape = 1) + 
  geom_smooth(method = "loess", se = FALSE) +
  labs(x = "Transformed Predicted Value", y = "Transformed Residual")
```
We can see that there doesn't seem to be any significant curvature in this graph, indicating that the constant variance assumption is correct.  
However, we can see that there is a large gap between the points, which shows that there seems to be a gap in observed the covariates (x values).  

## Transformed Predicted values vs. Absolute Transformed Residuals  
```{r}
#pred_prog_trans_abs = abs(mu_hat_transformed)
res_prog_trans_abs = abs(res_prog_trans)

tibble(x = mu_hat_transformed, y = res_prog_trans_abs) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_hline(yintercept = 0.8, linetype = "dashed") + 
  geom_point(shape = 1) +
  geom_smooth(method = "loess", se = FALSE) +
  labs(x = "Transformed Predicted Value", y = "Absolute Transformed Residual")
```
Using the loess smoothed curve, we can see that there is not a noticable departure from the straight line centered at approximately 0.8. The smoothed curve is relatively straight, but is centered around 0.8. This indicates that the model for the variance (and covariance) is adequate.  

## Mahalanobis Data  
```{r}
mahalanobis_data = tibble(id = aids$id, r_star = res_prog_trans) %>% group_by(id) %>% 
  nest()

mahalanobis_data = mahalanobis_data %>% 
  mutate(df = map_dbl(data, ~nrow(.x)))

mahalanobis_dist = function(x){
  x = as.matrix(x)
  t(x) %*% x
}

mahalanobis_data = mahalanobis_data %>% 
  mutate(d = map_dbl(data, ~mahalanobis_dist(.x)))

mahalanobis_data = mahalanobis_data %>% 
  mutate(p_value = pchisq(d, df, lower.tail = FALSE))


mahalanobis_data_p = mahalanobis_data %>% 
  arrange(p_value)

mahalanobis_data_p %>% filter(p_value <=.05)

```

```{r}
#expected outliers are

expected = 5036 *.05
expected
```

Using the mahalanobis data, we can see that we have 129 subjects who have a p-value < 0.05. From the size of our data, we expect that we will have 251.8 outliers. Our actual 129 outliers fall within the range of 251.8, so we do not need to be concerned about the outliers we find here and see in the QQ-plot.  

## Semi-Variogram  
```{r}
aids = aids %>% 
  mutate(occasion_sqr = occasion ^ 2)

Variogram(model_quadratic,
          data = aids,
          form = ~ occasion + occasion_sqr| id,
          resType = "normalized") %>% 
  as_tibble() %>% 
  ggplot(aes(x = dist, y = variog)) + 
  geom_hline(yintercept = 1, linetype = "dashed") +
  geom_point(shape = 1) +
  geom_smooth(method = "loess", se = FALSE, span = .2)
```


Looking at the semi-variogram, we can see that the loess smoothed curve does seem to fluctuate randomly around 1.0, but has a general decreasing trend. This looks similar to the semi-variograms we have seen in lecture, so we can infer that the model's covariance matrix is adequate.   




